<!DOCTYPE html>
<html lang="zh-cn" class="lang-zh-cn">
    <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="keywords" content="Layout,DeepLearning,ECNU,ICA,ICA-702," /><meta name="description" content="Donut论文解读" />
<meta itemprop="description" content="Donut论文解读" />
<meta http-equiv="X-UA-Compatible" content="ie=edge" />
<meta itemprop="name" content="不需要OCR的文档理解Transformer：Donut - ECNU ICALK 702" />
<link href="http://localhost:1313/index.xml" title="不需要OCR的文档理解Transformer：Donut - ECNU ICALK 702" type="application/rss+xml" rel="alternate" />
<title>不需要OCR的文档理解Transformer：Donut - ECNU ICALK 702</title><link rel="stylesheet" href="/main.css" /><meta property="og:site_name" content="不需要OCR的文档理解Transformer：Donut - ECNU ICALK 702" />
<meta property="og:type" content="article" />
<meta property="og:title" content="不需要OCR的文档理解Transformer：Donut" />
<meta property="og:description" content="Donut论文解读" />
<meta property="og:url" content="http://localhost:1313/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/" /><meta property="og:image" content="http://localhost:1313/featured.png" /><meta property="og:image:width" content="1366" /><meta property="og:image:height" content="768" /><meta property="article:publisher" content="http://localhost:1313/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/" /><meta property="article:published_time" content="2022-10-20T10:34:49&#43;08:00" /><meta property="article:modified_time" content="2022-10-20T12:43:04&#43;08:00" /><meta name="theme-color" content="#dd6065" />
<meta name="mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-title" content="不需要OCR的文档理解Transformer：Donut - ECNU ICALK 702" />
<meta name="apple-mobile-web-app-status-bar-style" content="white" />
<meta name="twitter:card" content="summary_large_image" /><meta name="twitter:site" content="@" />
    <meta name="twitter:creator" content="@" /><meta name="twitter:title" content="不需要OCR的文档理解Transformer：Donut - ECNU ICALK 702" />
<meta name="twitter:description" content="Donut论文解读" />
<meta name="twitter:url" content="http://localhost:1313/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/" /><meta name="twitter:image" content="http://localhost:1313/featured.png" /><link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" /><link rel="manifest" href="/manifest.json" /><link href="/icon.png" rel="shortcut icon" />
<link href="/icon.png" rel="Bookmark" />
<link rel="apple-touch-icon" href="/icon.png" /><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "headline": "不需要OCR的文档理解Transformer：Donut",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http:\/\/localhost:1313\/2022\/10\/20\/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html\/"
  },"genre": "posts","keywords": "Layout","wordcount": 4286 ,
  "url": "http:\/\/localhost:1313\/2022\/10\/20\/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html\/","datePublished": "2022-10-20T10:34:49\u002b08:00","dateModified": "2022-10-20T12:43:04\u002b08:00","author": {
    "@type": "Person",
    "name": "ecnu-cs-ica"
  },"description": ""
}
</script>


    </head>
    
    <body class="dark:bg-darkBg dark:text-darkText">
        <div class="relative mx-auto shadow-lg md:max-w-4xl xl:max-w-4xl 2xl:max-w-4xl">
            <div class="main flex flex-col justify-between bg-white dark:bg-darkFg"><header class="relative"><nav id="nav" class="navbar top-0 z-10 flex items-center border-b px-5 py-6 dark:border-darkBorder md:px-10">
        <div class="route-items flex w-full items-center justify-around"><a
                    title="首页"
                    data-active-link="/"
                    href="/"
                    class=" relative flex cursor-pointer flex-col items-center text-gray-700 transition duration-150 ease-[ease]"
                >
                    <i
                        class="eva eva-home flex h-8 w-8 items-center justify-center text-3xl leading-none text-gray-500 transition duration-150 ease-[ease] dark:text-darkTextPlaceholder"
                    ></i>
                    <span class="mt-1 block text-xs text-gray-400 dark:text-darkText sm:text-sm md:hidden">首页</span>
                </a><a
                    title="关于我"
                    data-active-link="/about/"
                    href="/about/"
                    class=" relative flex cursor-pointer flex-col items-center text-gray-700 transition duration-150 ease-[ease]"
                >
                    <i
                        class="eva eva-heart flex h-8 w-8 items-center justify-center text-3xl leading-none text-gray-500 transition duration-150 ease-[ease] dark:text-darkTextPlaceholder"
                    ></i>
                    <span class="mt-1 block text-xs text-gray-400 dark:text-darkText sm:text-sm md:hidden">关于我</span>
                </a><a
                    title="朋友们"
                    data-active-link="/links/"
                    href="/links/"
                    class=" relative flex cursor-pointer flex-col items-center text-gray-700 transition duration-150 ease-[ease]"
                >
                    <i
                        class="eva eva-people flex h-8 w-8 items-center justify-center text-3xl leading-none text-gray-500 transition duration-150 ease-[ease] dark:text-darkTextPlaceholder"
                    ></i>
                    <span class="mt-1 block text-xs text-gray-400 dark:text-darkText sm:text-sm md:hidden">朋友们</span>
                </a><a
                    title="归档"
                    data-active-link="/archives/"
                    href="/archives/"
                    class=" relative flex cursor-pointer flex-col items-center text-gray-700 transition duration-150 ease-[ease]"
                >
                    <i
                        class="eva eva-bar-chart flex h-8 w-8 items-center justify-center text-3xl leading-none text-gray-500 transition duration-150 ease-[ease] dark:text-darkTextPlaceholder"
                    ></i>
                    <span class="mt-1 block text-xs text-gray-400 dark:text-darkText sm:text-sm md:hidden">归档</span>
                </a><a
                    title="Weibo"
                    data-active-link="/weibo/"
                    href="/weibo/"
                    class=" relative flex cursor-pointer flex-col items-center text-gray-700 transition duration-150 ease-[ease]"
                >
                    <i
                        class="iconfont icon-weibo flex h-8 w-8 items-center justify-center text-3xl leading-none text-gray-500 transition duration-150 ease-[ease] dark:text-darkTextPlaceholder"
                    ></i>
                    <span class="mt-1 block text-xs text-gray-400 dark:text-darkText sm:text-sm md:hidden">Weibo</span>
                </a><a
                    title="GitHub"
                    data-active-link="/github/"
                    href="/github/"
                    class=" relative flex cursor-pointer flex-col items-center text-gray-700 transition duration-150 ease-[ease]"
                >
                    <i
                        class="eva eva-github flex h-8 w-8 items-center justify-center text-3xl leading-none text-gray-500 transition duration-150 ease-[ease] dark:text-darkTextPlaceholder"
                    ></i>
                    <span class="mt-1 block text-xs text-gray-400 dark:text-darkText sm:text-sm md:hidden">GitHub</span>
                </a><a
                    title="搜索"
                    data-active-link="/search/"
                    href="/search/"
                    class=" relative flex cursor-pointer flex-col items-center text-gray-700 transition duration-150 ease-[ease]"
                >
                    <i
                        class="eva eva-search flex h-8 w-8 items-center justify-center text-3xl leading-none text-gray-500 transition duration-150 ease-[ease] dark:text-darkTextPlaceholder"
                    ></i>
                    <span class="mt-1 block text-xs text-gray-400 dark:text-darkText sm:text-sm md:hidden">搜索</span>
                </a>
        </div>
    </nav><nav class="sub-navbar z-10 flex items-center border-b px-5 py-2 dark:border-darkBorder md:px-10"><a
                title="分类"
                data-active-link="/categories/"
                href="/categories/"
                class=" relative flex cursor-pointer items-center mr-4 text-gray-400 dark:text-darkText transition duration-150 ease-[ease] hover:text-theme"
            >
                <i
                    class="eva eva-folder leading-none mr-1"
                ></i>
                <span>分类</span>
            </a><a
                title="标签"
                data-active-link="/tags/"
                href="/tags/"
                class=" relative flex cursor-pointer items-center mr-4 text-gray-400 dark:text-darkText transition duration-150 ease-[ease] hover:text-theme"
            >
                <i
                    class="eva eva-pricetags leading-none mr-1"
                ></i>
                <span>标签</span>
            </a></nav><div class="dark-mode-switch absolute right-0 top-0 z-10 cursor-pointer pr-2 pt-2 text-xl leading-none">
    <i class="eva eva-moon opacity-20 dark:opacity-70"></i>
</div>
</header>
<main class="relative flex flex-grow " id="swup"><style>:root {
        --font:Times New Roman,Times,Heti Song,serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol;
    }</style><div class="type-posts layout- w-full"><div class="relative h-full">
    <div class="relative h-full">
        <div class="page-view-article flex h-full flex-col bg-white dark:bg-darkFg"><div class="relative"><div>
    <div class="-mb-2 w-full p-6 pb-0 text-3xl md:px-10">
        不需要OCR的文档理解Transformer：Donut
    </div>
</div></div><div class="article-info border-b p-6 pb-3 text-sm dark:border-darkBorder md:px-10">
    <div>
        <div class="mb-3 mr-4 inline-flex items-center sm:rounded-full">
            <i class="eva eva-clock-outline mr-1"></i>
            <span>
                <time
                    title="发布于 2022年10月20日 10:34:49"datetime="2022-10-20T10:34:49+08:00">2022年10月20日</time
                >
            </span>
        </div><div class="mb-3 mr-4 inline-flex items-center sm:rounded-full">
                <i class="eva eva-flag-outline mr-1"></i>
                <span>9 分钟</span>
            </div></div><div class="mb-3 flex items-center">
            <i class="eva eva-pricetags-outline mr-1"></i>
            <span class="mr-3">标签</span><a href="/tags/layout" title="Layout" class="group mr-2 flex items-center text-sm">
                    <i class="mr-1 text-gray-400 group-hover:text-theme">#</i>
                    <span class="text-gray-400 group-hover:text-theme">Layout</span>
                </a></div><div class="mb-3 flex items-center">
            <i class="eva eva-folder-outline mr-1"></i>
            <span class="mr-3">分类</span><a href="/categories/deeplearning" title="DeepLearning" class="group flex items-center text-sm">
                    <span class="text-gray-400 group-hover:text-theme">DeepLearning</span>
                    <span class="mx-0.5 group-last:hidden">,</span>
                </a></div></div><aside
            class="toc border-b border-gray-300 px-5 py-5 dark:border-darkBorder md:px-10 2xl:fixed 2xl:top-10 2xl:m-0 2xl:-ml-72 2xl:w-72 2xl:border-none 2xl:p-0 2xl:py-4 2xl:pr-4 "
        >
            <header>
                <h1 class="mb-3 text-2xl font-bold 2xl:mb-4">文章目录</h1>
            </header>
            <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#abstract">Abstract:</a></li>
        <li><a href="#1introduction">1.introduction</a></li>
        <li><a href="#2方法">2.方法</a></li>
        <li><a href="#3实验与分析">3.实验与分析</a></li>
        <li><a href="#32-设置-略">3.2 设置 略</a></li>
        <li><a href="#33-结果">3.3 结果</a></li>
        <li><a href="#4相关工作-略">4.相关工作 略</a></li>
        <li><a href="#5结论">5.结论</a></li>
      </ul>
    </li>
  </ul>
</nav>
        </aside><section class="article-content typo relative flex-grow px-6 py-5 md:px-10"><i title="更快的阅读" id="bionicReading" class="absolute right-0 top-0 cursor-pointer p-3"
            ><svg class="w-4 h-4 fill-current text-gray-400" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="10811" ><path d="M480 192c-19.2 0-32-12.8-32-32v-128c0-19.2 12.8-32 32-32s32 12.8 32 32v128c0 19.2-12.8 32-32 32zM160 1024c-6.4 0-19.2 0-25.6-6.4l-128-128c0-6.4-6.4-19.2-6.4-25.6s6.4-19.2 6.4-25.6l512-512c12.8-6.4 38.4-6.4 51.2 0l128 128c0 6.4 6.4 19.2 6.4 25.6s-6.4 19.2-6.4 25.6l-512 512c-6.4 6.4-19.2 6.4-25.6 6.4z m-83.2-160l83.2 83.2 467.2-467.2-83.2-83.2-467.2 467.2zM992 576h-128c-19.2 0-32-12.8-32-32s12.8-32 32-32h128c19.2 0 32 12.8 32 32s-12.8 32-32 32zM768 288c-6.4 0-19.2 0-25.6-6.4-12.8-12.8-12.8-32 0-44.8l96-96c12.8-12.8 32-12.8 44.8 0s12.8 32 0 44.8l-96 96c0 6.4-12.8 6.4-19.2 6.4zM256 288c-6.4 0-19.2 0-25.6-6.4L134.4 185.6c-6.4-12.8-6.4-38.4 0-51.2s32-12.8 44.8 0l96 96c12.8 12.8 12.8 32 0 44.8 0 12.8-12.8 12.8-19.2 12.8zM864 896c-6.4 0-19.2 0-25.6-6.4l-96-96c-12.8-12.8-12.8-32 0-44.8s32-12.8 44.8 0l96 96c12.8 12.8 12.8 32 0 44.8 0 6.4-12.8 6.4-19.2 6.4z" p-id="10812"></path><path d="M544 640c-6.4 0-19.2 0-25.6-6.4l-128-128c-6.4-12.8-6.4-38.4 0-51.2s32-12.8 44.8 0l128 128c12.8 12.8 12.8 38.4 6.4 51.2-6.4 6.4-19.2 6.4-25.6 6.4z" p-id="10813"></path></svg></i
        >

<h1 class="group " id="donut--document-understanding-transformer-without-ocr"
    >Donut : Document Understanding Transformer without OCR<a href="#donut--document-understanding-transformer-without-ocr"
        ><i class="eva eva-link ml-3 align-middle text-theme opacity-0 transition ease-in-out group-hover:opacity-100"></i></a
></h1>



<h3 class="group " id="abstract"
    >Abstract:<a href="#abstract"
        ><i class="eva eva-link ml-3 align-middle text-theme opacity-0 transition ease-in-out group-hover:opacity-100"></i></a
></h3>

<p>Understanding document images (e.g., invoices) has been an important research topic and has many applications in document processing automation. Through the latest advances in deep learning-based Optical Character Recognition (OCR), current Visual Document Understanding (VDU) systems have come to be designed based on OCR. Although such OCR-based approach promise reasonable performance, they suffer from critical problems induced by the OCR, e.g., (1) expensive computational costs and (2) performance degradation due to the OCR error propagation. In this paper, we propose a novel VDU model that is end-to-end trainable without underpinning OCR framework. To this end, we propose a new task and a synthetic document image generator to pre-train the model to mitigate the dependencies on largescale real document images. Our approach achieves state-of-the-art performance on various document understanding tasks in public benchmark datasets and private industrial service datasets. Through extensive experiments and analysis, we demonstrate the effectiveness of the proposed model especially with consideration for a real-world application.</p>


<h3 class="group " id="1introduction"
    >1.introduction<a href="#1introduction"
        ><i class="eva eva-link ml-3 align-middle text-theme opacity-0 transition ease-in-out group-hover:opacity-100"></i></a
></h3>

<p>半结构化文档，如发票、收据和名片，通常在现代工作环境中处理。其中一些文件以数字电子文件的形式存在，而另一些则以扫描图像甚至照片的形式存在。视觉文档理解（VDU）是一项旨在理解文档图像的任务，尽管其格式、布局和内容各不相同。VDU是自动化文档处理的重要步骤。其以下各种应用包括文档分类、解析和视觉问答。</p>
<p>通过基于深度学习的光学字符识别（OCR）的显著进步，大多数现有的VDU系统共享类似的架构，该架构依赖于单独的OCR模块从目标文档图像中提取文本信息。系统将OCR提取的文本信息作为输入，并使用OCR提取文本执行其自身的目标。例如，一个当前部署的名片和收据图像文档解析系统，由三个单独的文本检测、文本识别和解析模块组成（见图2）。</p>
<p><figure
    
        class="gallery-image" style=" flex-grow:190; flex-basis:456px"
    
>
    <picture class="noscript-hidden"><source data-srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%871_hu4b3307724b8c44ae005c725e81679f8b_247062_989x0_resize_q95_h2_catmullrom_3.webp 1080w" type="image/webp" /><img
            style="background-image: linear-gradient(180deg,#e0dedb, #ccc);"
            data-src="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%871.png"
            src="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%871_hu4b3307724b8c44ae005c725e81679f8b_247062_a0cebe948056384c0dbd11ee8f2b10b0.jpg"width="989"height="520"data-srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%871_hu4b3307724b8c44ae005c725e81679f8b_247062_989x0_resize_catmullrom_3.png 1080w"data-zoomable
            data-lazyload data-lazyload-blur
        />
    </picture>
    <noscript data-lazyload-noscript>
        <a class="after:hidden" href="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%871.png" target="_blank" rel="noopener noreferrer">
            <picture><source srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%871_hu4b3307724b8c44ae005c725e81679f8b_247062_989x0_resize_q95_h2_catmullrom_3.webp 1080w" type="image/webp" /><img
                    src="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%871.png"width="989"height="520"srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%871_hu4b3307724b8c44ae005c725e81679f8b_247062_989x0_resize_catmullrom_3.png 1080w"/>
            </picture>
        </a>
    </noscript></figure></p>
<p>然而，在实践中，这种方法存在几个问题。训练OCR很昂贵，商用OCR可能会出现一系列错误，OCR错误会对后续过程产生负面影响。</p>
<p>作者通过建模从原始输入图像到所需输出的直接映射，超越了传统框架。提出的模型甜甜圈是端到端可训练的，不依赖于任何其他模块（例如OCR），也就是说，模型是完整的。除此之外，为了减轻对大规模真实文档图像的依赖，作者还介绍了合成文档生成器SynthDoG及其在模型预训练中的应用。虽然想法很简单，但作者在各种数据集（包括真实工业基准）上的实验表明了作者的建议的有效性。这项工作的贡献总结如下：</p>
<p>1.提出了一种新的视觉文档理解方法。这是第一种基于以端到端方式训练的简单无OCR Transformer架构的方法。<br>
2.为所提出的模型提供了一个合成文档图像生成器和一个简单的预训练任务。<br>
3.对公共基准和私人工业服务数据集进行了广泛的实验和分析，表明所提出的方法不仅实现了最先进的性能，而且在实际应用中具有许多实际优势（例如，成本效益）。</p>


<h3 class="group " id="2方法"
    >2.方法<a href="#2%e6%96%b9%e6%b3%95"
        ><i class="eva eva-link ml-3 align-middle text-theme opacity-0 transition ease-in-out group-hover:opacity-100"></i></a
></h3>



<h4 class="group " id="21-背景"
    >2.1 背景<a href="#21-%e8%83%8c%e6%99%af"
        ><i class="eva eva-link ml-3 align-middle text-theme opacity-0 transition ease-in-out group-hover:opacity-100"></i></a
></h4>

<p>已有各种视觉文档理解（VDU）方法来理解和提取半结构化文档中的基本信息，如收据、发票和文档表单。</p>
<p>VDU中的早期尝试采用了基于视觉的方法，表明了文本理解在VDU中重要性。随着BERT的出现，大多数最先进的技术将计算机视觉（CV）和自然语言处理（NLP）技术结合在一起，近年来取得了显著的进步。</p>
<p>最新的方法共享一种通用方法，即使用大规模真实文档图像数据集，并依赖于一个单独的OCR引擎，其中模型在大量真实文档图像上进行预训练。在测试阶段，OCR引擎对看不见的图像执行操作以提取文本信息，然后将文本信息提供给后面的模块以实现其自身目标。因此，需要额外的努力，通过使用重型OCR引擎来确保整个VDU模型的性能。</p>


<h4 class="group " id="22-文档理解transformer"
    >2.2 文档理解Transformer<a href="#22-%e6%96%87%e6%a1%a3%e7%90%86%e8%a7%a3transformer"
        ><i class="eva eva-link ml-3 align-middle text-theme opacity-0 transition ease-in-out group-hover:opacity-100"></i></a
></h4>

<p>作者提出了一个简单的基于转换器的编码器-解码器模型，称为文档理解转换器（Donut），它是一种端到端的模型，不依赖于任何其他模块，如OCR。作者旨在设计基于转换器的简单架构。Dount由视觉编码器和文本解码器模块组成。该模型将输入文档图像直接映射为一对一转换为所需结构化格式的令牌序列。提出模型的概述如图3所示。</p>
<p><figure
    
        class="gallery-image" style=" flex-grow:237; flex-basis:569px"
    
>
    <picture class="noscript-hidden"><source data-srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%872_hu62adc57d30b59822f1b40affa37668c8_121701_983x0_resize_q95_h2_catmullrom_3.webp 1080w" type="image/webp" /><img
            style="background-image: linear-gradient(180deg,#f1f0f0, #ccc);"
            data-src="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%872.png"
            src="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%872_hu62adc57d30b59822f1b40affa37668c8_121701_38e93f2ecf82092aa8c13234f256a152.jpg"width="983"height="414"data-srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%872_hu62adc57d30b59822f1b40affa37668c8_121701_983x0_resize_catmullrom_3.png 1080w"data-zoomable
            data-lazyload data-lazyload-blur
        />
    </picture>
    <noscript data-lazyload-noscript>
        <a class="after:hidden" href="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%872.png" target="_blank" rel="noopener noreferrer">
            <picture><source srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%872_hu62adc57d30b59822f1b40affa37668c8_121701_983x0_resize_q95_h2_catmullrom_3.webp 1080w" type="image/webp" /><img
                    src="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%872.png"width="983"height="414"srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%872_hu62adc57d30b59822f1b40affa37668c8_121701_983x0_resize_catmullrom_3.png 1080w"/>
            </picture>
        </a>
    </noscript></figure></p>
<p><strong>编码器。</strong> 视觉编码器转换输入文档图像x∈RH×W×C到嵌入集{zi|zi∈Rd，1≤i≤n} 其中n是特征图大小或图像块的数量，d是编码器的潜在向量的维数。基于CNN的模型或基于Transformer的模型可以用作编码器网络。在本研究中，如果没有另外提及，作者使用Swin Transformer，因为它在作者的文档解析初步研究中显示了最佳性能。Swin Transformer首先将输入图像x分割为非重叠面片。然后，以下Swin Transformer块，其中内部具有移动窗口的局部自注意力机制，区域合并层应用于区域token。解码器中使用最终Swin Transforemr块{z}的输出。</p>
<p><strong>解码器。</strong> 给定表示{z}，文本解码器生成令牌序列（yi）m1，其中yi∈Rv是令牌i的一个独热向量，v是令牌词汇表的大小，m分别是超参数。作者使用BART作为解码器架构；具体而言，作者使用多语言BART模型。为了满足各种实际应用程序的适用速度和内存要求，作者使用了BART的前4层。</p>
<p><strong>模型输入。</strong> 模型训练是以教师强迫的方式进行的。在测试阶段，受GPT-3的启发，模型在给出提示的情况下生成令牌序列。在作者的实验中，作者简单地为每个下游任务的提示引入了一些新的特殊标记。作者在应用程序中使用的提示与所需的输出序列一起显示在图3中。</p>
<p><strong>输出转换。</strong> 输出令牌序列被转换为期望的结构化格式。作者采用JSON格式，因为它具有很高的表示能力。如图3所示，令牌序列与JSON数据是一对一可逆的。作者只需添加两个特殊标记[START]_∗] 及[END]_∗] 按字段∗。如果输出令牌序列的结构错误（例如，只有[START_name]存在，但没有[END_name]），作者只是将字段“name”视为丢失。该算法可以很容易地用一些正则表达式实现。</p>
<p><figure
    
        class="gallery-image" style=" flex-grow:180; flex-basis:434px"
    
>
    <picture class="noscript-hidden"><source data-srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%873_huf7a8a730df272ca5680b061e5a5ecd6c_73350_483x0_resize_q95_h2_catmullrom_3.webp 1080w" type="image/webp" /><img
            style="background-image: linear-gradient(180deg,#e5e4e4, #ccc);"
            data-src="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%873.png"
            src="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%873_huf7a8a730df272ca5680b061e5a5ecd6c_73350_030e8684d8f7e6d63e80297109c8a47c.jpg"width="483"height="267"data-srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%873_huf7a8a730df272ca5680b061e5a5ecd6c_73350_483x0_resize_catmullrom_3.png 1080w"data-zoomable
            data-lazyload data-lazyload-blur
        />
    </picture>
    <noscript data-lazyload-noscript>
        <a class="after:hidden" href="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%873.png" target="_blank" rel="noopener noreferrer">
            <picture><source srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%873_huf7a8a730df272ca5680b061e5a5ecd6c_73350_483x0_resize_q95_h2_catmullrom_3.webp 1080w" type="image/webp" /><img
                    src="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%873.png"width="483"height="267"srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%873_huf7a8a730df272ca5680b061e5a5ecd6c_73350_483x0_resize_catmullrom_3.png 1080w"/>
            </picture>
        </a>
    </noscript></figure></p>


<h4 class="group " id="23-预训练"
    >2.3 预训练<a href="#23-%e9%a2%84%e8%ae%ad%e7%bb%83"
        ><i class="eva eva-link ml-3 align-middle text-theme opacity-0 transition ease-in-out group-hover:opacity-100"></i></a
></h4>

<p>VDU的当前技术水平严重依赖大规模真实文档图像来训练模型。然而，这种方法在现实生产环境中并不总是可用的，特别是在处理英语以外的多种语言时。</p>
<p><strong>合成文档生成器。</strong> 为了消除对大规模真实文档图像的依赖，作者提出了一种可伸缩的合成文档生成器，称为SynthDoG。渲染图像的流程基本上遵循Yim等人。如图4所示，生成的图像由几个组件组成；背景、文档、文本和布局。背景图像从ImageNet中采样，文档纹理从收集的照片中采样。单词和短语取自维基百科。应用基于规则的随机模式来模拟真实文档中的复杂布局。此外，图像渲染中的一些主要技术被应用于模拟真实照片。SynthDoG生成的示例图像如图5所示。</p>
<p><figure
    
        class="gallery-image" style=" flex-grow:166; flex-basis:400px"
    
>
    <picture class="noscript-hidden"><source data-srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%874_hub880acc196caf41c7ee82035d8e562ce_470791_978x0_resize_q95_h2_catmullrom_3.webp 1080w" type="image/webp" /><img
            style="background-image: linear-gradient(180deg,#ccc8c6, #6e6964);"
            data-src="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%874.png"
            src="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%874_hub880acc196caf41c7ee82035d8e562ce_470791_70a7c80dc81b60d9b3314f6730f33c17.jpg"width="978"height="586"data-srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%874_hub880acc196caf41c7ee82035d8e562ce_470791_978x0_resize_catmullrom_3.png 1080w"data-zoomable
            data-lazyload data-lazyload-blur
        />
    </picture>
    <noscript data-lazyload-noscript>
        <a class="after:hidden" href="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%874.png" target="_blank" rel="noopener noreferrer">
            <picture><source srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%874_hub880acc196caf41c7ee82035d8e562ce_470791_978x0_resize_q95_h2_catmullrom_3.webp 1080w" type="image/webp" /><img
                    src="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%874.png"width="978"height="586"srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%874_hub880acc196caf41c7ee82035d8e562ce_470791_978x0_resize_catmullrom_3.png 1080w"/>
            </picture>
        </a>
    </noscript></figure></p>
<p><strong>任务。</strong> 作者使用SynthDoG生成了120万张合成文档图像。作者使用了从英语、韩语和日语维基百科中提取的语料库，并为每种语言生成了400K图像。任务很简单。模型被训练为按照从左上到右下的读取顺序读取图像中的所有文本。示例如图3所示。</p>


<h4 class="group " id="24-应用"
    >2.4 应用<a href="#24-%e5%ba%94%e7%94%a8"
        ><i class="eva eva-link ml-3 align-middle text-theme opacity-0 transition ease-in-out group-hover:opacity-100"></i></a
></h4>

<p>在模型学习如何阅读之后，在应用程序阶段（即微调），作者教模型如何理解给定的文档图像。如图3所示，作者将所有下游任务解释为JSON预测问题。</p>
<p>解码器被训练以生成表示所需输出信息的JSON。例如，在文档分类任务中，解码器被训练以生成令牌序列[START_class][memo][END_class]，该令牌序列1到1可逆为JSON｛“class”：“memo”｝。作者引入了一些特殊的标记（例如，[memo]用于表示类“memo”），如果这种替换在目标下游任务中可用。</p>


<h3 class="group " id="3实验与分析"
    >3.实验与分析<a href="#3%e5%ae%9e%e9%aa%8c%e4%b8%8e%e5%88%86%e6%9e%90"
        ><i class="eva eva-link ml-3 align-middle text-theme opacity-0 transition ease-in-out group-hover:opacity-100"></i></a
></h3>



<h4 class="group " id="31-下游任务与数据集"
    >3.1 下游任务与数据集<a href="#31-%e4%b8%8b%e6%b8%b8%e4%bb%bb%e5%8a%a1%e4%b8%8e%e6%95%b0%e6%8d%ae%e9%9b%86"
        ><i class="eva eva-link ml-3 align-middle text-theme opacity-0 transition ease-in-out group-hover:opacity-100"></i></a
></h4>

<p>作者在下面的数据集上提供了作者运行实验的下游任务。数据集示例如图5所示。</p>


<h4 class="group " id="311-文档分类"
    >3.1.1 文档分类<a href="#311-%e6%96%87%e6%a1%a3%e5%88%86%e7%b1%bb"
        ><i class="eva eva-link ml-3 align-middle text-theme opacity-0 transition ease-in-out group-hover:opacity-100"></i></a
></h4>

<p>为了查看模型是否理解文档类型，作者测试了文档分类任务。使用RVL-CDIP数据集。与其他通过编码token嵌入上的softmax预测类标签的模型不同，作者使解码器生成包含类标签信息的JSON，以保持任务解决方法的一致性。作者报告了测试集的总体分类精度。</p>


<h4 class="group " id="312-文档解析"
    >3.1.2 文档解析<a href="#312-%e6%96%87%e6%a1%a3%e8%a7%a3%e6%9e%90"
        ><i class="eva eva-link ml-3 align-middle text-theme opacity-0 transition ease-in-out group-hover:opacity-100"></i></a
></h4>

<p>为了使模型完全理解给定文档图像中的复杂布局、格式和内容，作者进行文档解析，这是从输入文档图像中提取所需结构化信息的任务（见图2）。使用Indonesian Receipts数据集、Japanese Business Cards数据集和Korean Receipts数据集。</p>


<h4 class="group " id="313-document-vqa"
    >3.1.3 Document VQA<a href="#313-document-vqa"
        ><i class="eva eva-link ml-3 align-middle text-theme opacity-0 transition ease-in-out group-hover:opacity-100"></i></a
></h4>

<p>为了验证模型的进一步能力，作者进行了文档视觉问答任务（DocVQA）。在这个任务中，给出了一个文档图像和一个自然语言问题，该模型通过理解图像中的视觉和文本信息来预测问题的正确答案。作者让解码器生成包含问题（给定）和答案（预测）的JSON，以保持方法的一致性。使用DocVQA数据集。</p>


<h3 class="group " id="32-设置-略"
    >3.2 设置 略<a href="#32-%e8%ae%be%e7%bd%ae-%e7%95%a5"
        ><i class="eva eva-link ml-3 align-middle text-theme opacity-0 transition ease-in-out group-hover:opacity-100"></i></a
></h3>



<h3 class="group " id="33-结果"
    >3.3 结果<a href="#33-%e7%bb%93%e6%9e%9c"
        ><i class="eva eva-link ml-3 align-middle text-theme opacity-0 transition ease-in-out group-hover:opacity-100"></i></a
></h3>



<h4 class="group " id="331-文档分类"
    >3.3.1 文档分类<a href="#331-%e6%96%87%e6%a1%a3%e5%88%86%e7%b1%bb"
        ><i class="eva eva-link ml-3 align-middle text-theme opacity-0 transition ease-in-out group-hover:opacity-100"></i></a
></h4>

<p>分类精度如表1所示。在不依赖OCR或大规模真实文档图像的情况下，提出的甜甜圈显示出与现有技术相当的性能。与其他基于transformer的模型不同，作者的模型的token嵌入可以在此任务中删除，因为推理是以端到端的方式进行的。</p>
<p><figure
    
        class="gallery-image" style=" flex-grow:298; flex-basis:715px"
    
>
    <picture class="noscript-hidden"><source data-srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%875_hu4c34a65cc3f382ca74147942651573e8_77821_990x0_resize_q95_h2_catmullrom_3.webp 1080w" type="image/webp" /><img
            style="background-image: linear-gradient(180deg,#efefef, #ccc);"
            data-src="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%875.png"
            src="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%875_hu4c34a65cc3f382ca74147942651573e8_77821_5996cb7281d42c30f8a71ff276e6c3ea.jpg"width="990"height="332"data-srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%875_hu4c34a65cc3f382ca74147942651573e8_77821_990x0_resize_catmullrom_3.png 1080w"data-zoomable
            data-lazyload data-lazyload-blur
        />
    </picture>
    <noscript data-lazyload-noscript>
        <a class="after:hidden" href="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%875.png" target="_blank" rel="noopener noreferrer">
            <picture><source srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%875_hu4c34a65cc3f382ca74147942651573e8_77821_990x0_resize_q95_h2_catmullrom_3.webp 1080w" type="image/webp" /><img
                    src="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%875.png"width="990"height="332"srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%875_hu4c34a65cc3f382ca74147942651573e8_77821_990x0_resize_catmullrom_3.png 1080w"/>
            </picture>
        </a>
    </noscript></figure></p>


<h4 class="group " id="332-文档解析"
    >3.3.2 文档解析<a href="#332-%e6%96%87%e6%a1%a3%e8%a7%a3%e6%9e%90"
        ><i class="eva eva-link ml-3 align-middle text-theme opacity-0 transition ease-in-out group-hover:opacity-100"></i></a
></h4>

<p>归一化树编辑距离（NTD）得分如表2所示。作者将提出的模型与多年来实际产品中的基线进行了比较。对于所有领域，包括公共和私人服务内数据集，作者提出的模型显示了对比模型中最佳的NTD分数。此外，推理时间显著减少，特别是对于具有高复杂度的领域，即韩语收据解析任务。这证明了作者的建议在实际应用中的有效性。</p>
<p><figure
    
        class="gallery-image" style=" flex-grow:289; flex-basis:693px"
    
>
    <picture class="noscript-hidden"><source data-srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%876_hu7d83e3c3d078ba5527a345b30b3ff674_105851_983x0_resize_q95_h2_catmullrom_3.webp 1080w" type="image/webp" /><img
            style="background-image: linear-gradient(180deg,#e9e9ea, #ccc);"
            data-src="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%876.png"
            src="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%876_hu7d83e3c3d078ba5527a345b30b3ff674_105851_8e980e177c7b5e2e393c7bc6de796350.jpg"width="983"height="340"data-srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%876_hu7d83e3c3d078ba5527a345b30b3ff674_105851_983x0_resize_catmullrom_3.png 1080w"data-zoomable
            data-lazyload data-lazyload-blur
        />
    </picture>
    <noscript data-lazyload-noscript>
        <a class="after:hidden" href="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%876.png" target="_blank" rel="noopener noreferrer">
            <picture><source srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%876_hu7d83e3c3d078ba5527a345b30b3ff674_105851_983x0_resize_q95_h2_catmullrom_3.webp 1080w" type="image/webp" /><img
                    src="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%876.png"width="983"height="340"srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%876_hu7d83e3c3d078ba5527a345b30b3ff674_105851_983x0_resize_catmullrom_3.png 1080w"/>
            </picture>
        </a>
    </noscript></figure></p>
<p>作为一个真实的产品，客户有时需要对提取的价值进行本地化。作者在图6中显示了给定一个看不见的印度尼西亚收据的解码器的交叉注意力图。它显示了模型关注给定图像中所需位置的有趣结果。使用简单的启发式方法，作者将注意力图转换为一个边界框，样本如图所示。尽管该模型不如商业OCR产品准确，但该模型显示了有意义的结果，可以用作辅助指标。</p>
<p><figure
    
        class="gallery-image" style=" flex-grow:94; flex-basis:226px"
    
>
    <picture class="noscript-hidden"><source data-srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%877_hu90350c7347ff33a4735f06f72ec8b771_189308_509x0_resize_q95_h2_catmullrom_3.webp 1080w" type="image/webp" /><img
            style="background-image: linear-gradient(180deg,#cdc0c4, #ccc);"
            data-src="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%877.png"
            src="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%877_hu90350c7347ff33a4735f06f72ec8b771_189308_b76a555b05e357703d52de65517a5e9b.jpg"width="509"height="539"data-srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%877_hu90350c7347ff33a4735f06f72ec8b771_189308_509x0_resize_catmullrom_3.png 1080w"data-zoomable
            data-lazyload data-lazyload-blur
        />
    </picture>
    <noscript data-lazyload-noscript>
        <a class="after:hidden" href="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%877.png" target="_blank" rel="noopener noreferrer">
            <picture><source srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%877_hu90350c7347ff33a4735f06f72ec8b771_189308_509x0_resize_q95_h2_catmullrom_3.webp 1080w" type="image/webp" /><img
                    src="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%877.png"width="509"height="539"srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%877_hu90350c7347ff33a4735f06f72ec8b771_189308_509x0_resize_catmullrom_3.png 1080w"/>
            </picture>
        </a>
    </noscript></figure></p>


<h4 class="group " id="333-document-vqa"
    >3.3.3 Document VQA<a href="#333-document-vqa"
        ><i class="eva eva-link ml-3 align-middle text-theme opacity-0 transition ease-in-out group-hover:opacity-100"></i></a
></h4>

<p>结果如表3所示。作者的方法在不依赖OCR和大规模真实文档图像（如IIT-CDIP）的情况下显示了一个有希望的结果。第三组的结果是最好的，因为他们均使用大规模扫描的英语文档数据集进行预训练。他们的分数与作者的分数之间的差距意味着预训练对大规模真实文档的影响，这将是作者未来要解决的问题之一。与比较方法相比，甜甜圈显示出合理的性能和更快的推理速度。</p>
<p>与其他方法相比，甜甜圈显示出合理的性能和更快的推理速度。为了展示甜甜圈的潜在能力，作者还通过使用DocVQA训练集的10K真实图像进行额外的预训练，展示了甜甜圈性能。虽然额外的预训练图像有噪声，并且图像数量很少（10K），但它会显著提高性能（47.14→ 53.14），这证明了真实文档图像的重要性。</p>
<p><figure
    
        class="gallery-image" style=" flex-grow:93; flex-basis:224px"
    
>
    <picture class="noscript-hidden"><source data-srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%878_hu2dd9c064f997f4eb9c35454234252071_95677_484x0_resize_q95_h2_catmullrom_3.webp 1080w" type="image/webp" /><img
            style="background-image: linear-gradient(180deg,#eaeaea, #ccc);"
            data-src="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%878.png"
            src="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%878_hu2dd9c064f997f4eb9c35454234252071_95677_89be6a936cdfd814567053992cb5e035.jpg"width="484"height="517"data-srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%878_hu2dd9c064f997f4eb9c35454234252071_95677_484x0_resize_catmullrom_3.png 1080w"data-zoomable
            data-lazyload data-lazyload-blur
        />
    </picture>
    <noscript data-lazyload-noscript>
        <a class="after:hidden" href="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%878.png" target="_blank" rel="noopener noreferrer">
            <picture><source srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%878_hu2dd9c064f997f4eb9c35454234252071_95677_484x0_resize_q95_h2_catmullrom_3.webp 1080w" type="image/webp" /><img
                    src="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%878.png"width="484"height="517"srcset="/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/%E5%9B%BE%E7%89%878_hu2dd9c064f997f4eb9c35454234252071_95677_484x0_resize_catmullrom_3.png 1080w"/>
            </picture>
        </a>
    </noscript></figure></p>


<h3 class="group " id="4相关工作-略"
    >4.相关工作 略<a href="#4%e7%9b%b8%e5%85%b3%e5%b7%a5%e4%bd%9c-%e7%95%a5"
        ><i class="eva eva-link ml-3 align-middle text-theme opacity-0 transition ease-in-out group-hover:opacity-100"></i></a
></h3>



<h3 class="group " id="5结论"
    >5.结论<a href="#5%e7%bb%93%e8%ae%ba"
        ><i class="eva eva-link ml-3 align-middle text-theme opacity-0 transition ease-in-out group-hover:opacity-100"></i></a
></h3>

<p>在这项工作中，作者提出了一种新的用于视觉文档理解的端到端方法。提出的方法Donut将输入文档图像直接映射到所需的结构化输出。与传统方法不同，作者的方法不依赖于OCR和大规模真实文档图像。作者还提出了一个合成文档图像生成器SynthDoG，它以课程学习的方式在模型的预训练中起着重要作用。作者通过提出的训练管道，逐步训练模型，从如何阅读到如何理解。作者在外部公共基准和私有内部服务数据集上的广泛实验和分析表明，该方法具有更高的性能和更好的成本效益。这是一个重大影响，因为目标任务已经在工业中实际使用。作者未来的工作是将提出的方法扩展到与文档理解相关的其他领域/任务。</p>
</section><div class="px-6 pb-5 pt-4 text-center text-xl text-gray-500 md:px-10 md:pb-10 md:pt-14 flex items-center justify-center"><a
                class="mr-4 inline-flex h-5 w-5 items-center"
                title="分享到 Twitter"
                href="https://twitter.com/share?&text=Donut%e8%ae%ba%e6%96%87%e8%a7%a3%e8%af%bb&url=http://localhost:1313/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/"
                target="_blank"
                rel="noopener noreferrer"
                ><i class="eva eva-twitter hover:text-theme"></i
            ></a><a
                class="mr-4 inline-flex h-5 w-5 items-center"
                title="分享到 Facebook"
                href="https://www.facebook.com/sharer.php?u=http://localhost:1313/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/"
                target="_blank"
                rel="noopener noreferrer"
                ><i class="eva eva-facebook hover:text-theme"></i
            ></a><a
                class="mr-4 inline-flex h-5 w-5 items-center"
                title="分享到微博"
                href="https://service.weibo.com/share/share.php?url=http://localhost:1313/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/&title=%e4%b8%8d%e9%9c%80%e8%a6%81OCR%e7%9a%84%e6%96%87%e6%a1%a3%e7%90%86%e8%a7%a3Transformer%ef%bc%9aDonut&sudaref=localhost%3a1313"
                target="_blank"
                rel="noopener noreferrer"
            ><svg class="inline-block h-5 w-5 fill-current hover:text-theme" viewBox="0 0 1193 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2681" width="200" height="200"> <path d="M456.991736 557.336482c-107.598583 0-194.644628 74.956316-194.644629 166.838252s87.046045 166.838253 194.644629 166.838253c107.598583 0 194.644628-74.956316 194.644628-166.838253s-87.046045-166.838253-194.644628-166.838252zM391.707202 822.101535c-36.269185 0-66.493506-27.806375-66.493507-62.866588s29.015348-62.866588 66.493507-62.866588c36.269185 0 66.493506 27.806375 66.493506 62.866588S427.976387 822.101535 391.707202 822.101535z m93.090909-91.881936c-14.507674 0-26.597403-12.089728-26.597403-26.597403s12.089728-26.597403 26.597403-26.597403 26.597403 12.089728 26.597403 26.597403-12.089728 26.597403-26.597403 26.597403zM239.376623 281.690673C97.9268 394.125148-18.134593 600.859504 30.224321 661.308146c32.642267 41.105077 59.239669-19.343566 124.524203-89.46399 30.224321-32.642267 77.374262-54.403778 122.106258-90.672964 20.552538-16.92562 197.062574-35.060213 230.913813-35.060212 97.9268-99.135773 114.85242-207.943329 74.956316-258.720189-48.358914-59.239669-201.898465-16.92562-343.348288 94.299882z" p-id="2682" ></path> <path d="M808.802834 560.9634C906.729634 461.827627 911.565525 377.199528 870.460449 326.422668c-47.149941-60.448642-211.570248-32.642267-351.811098 78.583235" p-id="2683" ></path> <path d="M605.695396 353.020071c-14.507674 8.46281-25.38843 12.089728-29.015349 7.253837-1.208973-2.417946-1.208973-6.044864 1.208973-9.671783-16.92562-1.208973-33.85124-1.208973-50.776859-1.208973C235.749705 349.393152 0 500.514758 0 686.696576s235.749705 337.303424 527.112161 337.303424 527.112161-151.121606 527.11216-337.303424c0-170.465171-194.644628-309.497048-448.528925-333.676505zM481.171192 959.924439C275.645809 959.924439 108.807556 847.489965 108.807556 708.458087s166.838253-251.466352 372.363636-251.466351 372.363636 112.434475 372.363637 251.466351-166.838253 251.466352-372.363637 251.466352z" p-id="2684" ></path> <path d="M1021.582054 423.140496c-3.626919 0-6.044864 0-9.671782-1.208973-18.134593-4.835891-29.015348-24.179457-22.970485-42.31405 2.417946-7.253837 3.626919-16.92562 3.626919-29.015348 0-65.284534-53.194805-119.688312-119.688312-119.688312-19.343566 0-33.85124-15.716647-33.851239-33.851239s15.716647-33.85124 33.851239-33.85124c103.971665 0 187.390791 84.628099 187.390791 187.390791 0 18.134593-2.417946 33.85124-6.044864 48.358914-4.835891 14.507674-18.134593 24.179457-32.642267 24.179457z" p-id="2685" ></path> <path d="M1146.106257 473.917355c-2.417946 0-6.044864 0-8.46281-1.208972-20.552538-4.835891-32.642267-25.38843-27.806375-45.940969 6.044864-24.179457 8.46281-47.149941 8.46281-71.329397C1118.299882 201.898465 991.357733 74.956316 836.609209 74.956316c-20.552538 0-37.478158-16.92562-37.478158-37.478158S816.056671 0 836.609209 0c197.062574 0 356.646989 159.584416 356.646989 356.646989 0 29.015348-3.626919 59.239669-10.880755 88.255018-3.626919 18.134593-19.343566 29.015348-36.269186 29.015348z" p-id="2686" ></path> </svg></a><i class="eva eva-copy mr-4 cursor-pointer hover:text-theme" title="复制链接" data-clipboard-text="http://localhost:1313/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/"></i><div class="group h-5 w-5 relative hidden cursor-pointer sm:inline-block">
                <i title="二维码" class="eva show-qrcode eva-smartphone hover:text-theme"></i>
                <div
                    class="qrcode-wrapper p-2 pointer-events-none absolute left-2/4 bottom-10 h-32 w-32 -translate-x-1/2 overflow-hidden rounded border border-gray-300 bg-white opacity-0 transition duration-300 ease-[ease] group-hover:opacity-100"
                >
                    <img class="h-full w-full" src="https://api.qrserver.com/v1/create-qr-code/?size=150x150&amp;data=http://localhost:1313/2022/10/20/%E4%B8%8D%E9%9C%80%E8%A6%81ocr%E7%9A%84%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3transformerdonut.html/" alt="二维码" />
                </div>
            </div></div>
<div class="border-b dark:border-darkBorder"></div><div class="flex justify-between px-2 py-4 text-xl md:px-6 md:text-2xl">
    <div>
        <a
            href="/2022/10/13/%E4%B8%80%E7%A7%8D%E5%A4%9A%E6%A8%A1%E6%80%81%E8%9E%8D%E5%90%88%E6%96%B9%E6%B3%95prefil.html/"
            title="一种多模态融合方法PreFIL"
            class="invisible flex cursor-pointer items-center text-gray-500 transition duration-300 ease-[ease] hover:text-theme dark:text-darkTextPlaceholder dark:hover:text-darkText"style="visibility: visible;">
            <span class="flex items-center text-5xl opacity-70 dark:bg-opacity-100">
                <i class="eva eva-chevron-left-outline"></i>
            </span>
            <span>上一篇</span>
        </a>
    </div><div class="hidden items-center text-xs xl:flex">
        除特殊声明外，本博客一律使用以下协议进行授权 「
        <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh" target="_blank" rel="noopener noreferrer" class="text-theme">署名 - 非商业性使用 - 禁止演绎 4.0</a>
        」
    </div>
    <div class="flex items-center text-sm xl:hidden">
        <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh" target="_blank" rel="noopener noreferrer" class="text-theme">
            <img src="/Cc-by-nc-nd.svg" alt="署名 - 非商业性使用 - 禁止演绎 4.0" title="署名 - 非商业性使用 - 禁止演绎 4.0" class="w-24" />
        </a>
    </div>

    <a
        href=""
        title=""
        class="invisible flex cursor-pointer items-center text-gray-500 transition duration-300 ease-[ease] hover:text-theme dark:text-darkTextPlaceholder dark:hover:text-darkText">
        <span>下一篇</span>
        <span class="flex items-center text-5xl opacity-70 dark:bg-opacity-100">
            <i class="eva eva-chevron-right-outline"></i>
        </span>
    </a>
</div>
<div class="border-t py-6 px-6 md:px-8 dark:border-darkBorder">
    <script src="https://giscus.app/client.js"
    data-repo="ecnu-ica22/ecnu-ica22.github.io"
    data-repo-id="R_kgDOIIrgSA"
    data-category="Gerernal"
    data-category-id="DIC_kwDOIIrgSM4CRznI"
    data-mapping="title"
    data-reactions-enabled="1"
    data-emit-metadata="0"
    data-input-position="bottom"
    data-theme="light"
    data-lang="zh-CN"
    data-loading="false"
    crossorigin="anonymous"
    data-swup-reload-script
    async
>
</script>

<script data-swup-reload-script>
    (function () {
        addEventListener("message", (e) => {
            if (event.origin !== "https://giscus.app") return;
            handler();
        });
        window.addEventListener("onThemeChange", handler);

        function handler() {
            if (document.documentElement.dataset.scheme === "light") {
                setGiscusTheme('light');
            } else {
                setGiscusTheme('dark');
            }
        }
    })();
    
    function setGiscusTheme(theme) {
        let giscus = document.querySelector("iframe.giscus-frame");
        if (giscus) {
            giscus.contentWindow.postMessage(
                {
                    giscus: {
                        setConfig: {
                            theme: theme,
                        },
                    },
                },
                "https://giscus.app"
            );
        }
    }
</script>
</div>

        </div>
    </div>
</div>
</div>
                </main><footer>
    <div
        class="com-footer flex flex-col items-center border-t py-4 px-4 text-sm leading-none text-gray-600 dark:border-darkBorder dark:text-darkTextPlaceholder md:flex-row md:justify-between"
    >
        <div class="mb-2 flex items-center justify-between text-center md:mb-0">
            <span class="">© 2022 - 2022</span>
            <span class="mx-1.5 opacity-50"> | </span>由 <a data-no-swup class="mx-1 font-bold hover:text-theme" href="https://gohugo.io/" target="_blank" rel="noopener noreferrer">Hugo</a> <span class="text-xs opacity-70">❤</span> <a data-no-swup class="mx-1 font-bold hover:text-theme" href="https://github.com/Ice-Hazymoon/hugo-theme-luna" target="_blank" rel="noopener noreferrer">Luna</a> 驱动</div>

        <div class="flex items-center"><span class="noscript-hidden mx-1.5 hidden opacity-50 md:block"> | </span><a data-no-swup href="http://localhost:1313/index.xml" target="_blank" class="mr-1.5 hover:text-theme">
                    <span class=" md:hidden lg:inline"><svg t="1650887361919" class="mr-0.5 w-96 w-3 fill-current text-inherit inline-block align-top" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3091"><path d="M320.16155 831.918c0 70.738-57.344 128.082-128.082 128.082S63.99955 902.656 63.99955 831.918s57.344-128.082 128.082-128.082 128.08 57.346 128.08 128.082z m351.32 94.5c-16.708-309.2-264.37-557.174-573.9-573.9C79.31155 351.53 63.99955 366.21 63.99955 384.506v96.138c0 16.83 12.98 30.944 29.774 32.036 223.664 14.568 402.946 193.404 417.544 417.544 1.094 16.794 15.208 29.774 32.036 29.774h96.138c18.298 0.002 32.978-15.31 31.99-33.58z m288.498 0.576C943.19155 459.354 566.92955 80.89 97.00555 64.02 78.94555 63.372 63.99955 77.962 63.99955 96.032v96.136c0 17.25 13.67 31.29 30.906 31.998 382.358 15.678 689.254 322.632 704.93 704.93 0.706 17.236 14.746 30.906 31.998 30.906h96.136c18.068-0.002 32.658-14.948 32.01-33.008z" p-id="3092"></path></svg></span>
                    <span>RSS</span>
                </a><a data-no-swup href="http://localhost:1313/sitemap.xml" target="_blank" class="mr-1.5 hover:text-theme">
                    <span class=" md:hidden lg:inline"><svg t="1650887940556" class="mr-0.5 w-3 fill-current text-inherit inline-block align-top" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6291"><path d="M950.044 625.778h-68.266v-56.89c0-45.51-39.822-85.332-85.334-85.332h-256v-85.334h68.267c39.822 0 73.956-34.133 73.956-73.955V130.844c0-39.822-34.134-73.955-73.956-73.955H415.29c-39.822 0-73.956 34.133-73.956 73.955v193.423c0 39.822 34.134 73.955 73.956 73.955h68.267v85.334h-256c-45.512 0-85.334 39.822-85.334 85.333v56.889H73.956C34.133 625.778 0 659.91 0 699.733v193.423c0 39.822 34.133 73.955 73.956 73.955h193.422c39.822 0 73.955-34.133 73.955-73.955V699.733c0-39.822-34.133-73.955-73.955-73.955H199.11v-56.89c0-17.066 11.378-28.444 28.445-28.444h568.888c17.067 0 28.445 11.378 28.445 28.445v56.889h-68.267c-39.822 0-73.955 34.133-73.955 73.955v193.423c0 39.822 34.133 73.955 73.955 73.955h193.422c39.823 0 73.956-34.133 73.956-73.955V699.733c0-39.822-34.133-73.955-73.956-73.955z" p-id="6292"></path></svg></span>
                    <span>Sitemap</span>
                </a><div id="google_translate_element" class="overflow-hidden rounded border dark:border-darkBorder"></div></div><div id="run-time" class="mt-2 flex-grow text-right md:mt-0">
    <span>运行时间： </span><b id="run-time-d">0</b>
    <span class="text-xs">天</span>
    <b id="run-time-h">0</b>
    <span class="text-xs">小时</span>
    <b id="run-time-m">0</b>
    <span class="text-xs">分钟</span>
    <b id="run-time-s">0</b>
    <span class="text-xs">秒</span>
</div>
</div>

    <script type="text/javascript">
window.__theme = {
    cdn: '',
    pjax: true ,
    isServer: true ,
    $version:"",
    lang: 'zh-cn',
    imageZoom: true ,
    lazyload: true ,
    bionicReading: {
        enabled: true ,
        skipLinks: false ,
        autoBionic: false ,
        excludeWords:[],
        excludeClasses:["github"],
        excludeNodeNames:[],
    },
    katex: true ,
    search: true ,
    backtop: true ,
    pangu: true ,
    autoDarkMode: true ,
    googleAnalytics:false,
    hugoEncrypt: {
        wrongPasswordText: '密码错误',
        userStorage:window['sessionStorage'],
    },
    console: {
        enabled: true ,
        leftColor: '#dd6065',
        rightColor: '#feb462',
        leftText: 'ECNU ICALK 702',
        rightText: 'Powered by Hugo Luna',
    },
    assets: {
        error_svg: "\/images\/error.svg",
        search_svg: "\/images\/search.svg",
    },
    i18n: {
        copy: {
            success: "复制成功",
            failed: "复制失败，请手动复制",
            copyCode: "复制代码",
        },
        search: {
            untitled: "无标题",
            loadFailure: "初始化搜索引擎失败",
            input: "请输入内容...",
        },
        darkMode: {
            dark: "切换到夜间模式",
            light: "切换到日间模式"
        }
    },creatTime: "2022\/10\/01"}
</script>
<script type="text/javascript" src="/ts/main.js" defer></script><script>
    if ('serviceWorker' in navigator) {
        window.addEventListener('load', function() {
            navigator.serviceWorker.register('\/sw.js');
        });
    }
</script>
<script type="text/javascript" src="/translate-google.js" defer></script><script type="text/javascript">
    window.translateelement_styles = "\/sass\/translateelement.min.c65796c6c3e4d48c75f72776948be83c5c448d1c5cc466b996b00657c558d28a.css";
    function googleTranslateElementInit(){
        new google.translate.TranslateElement({
            pageLanguage: 'zh-cn',
            includedLanguages: 'af,ga,sq,it,ar,ja,az,kn,eu,ko,bn,la,be,lv,bg,lt,ca,mk,zh-CN,ms,zh-TW,mt,hr,no,cs,fa,da,pl,nl,pt,en,ro,eo,ru,et,sr,tl,sk,fi,sl,fr,es,gl,sw,ka,sv,de,ta,el,te,gu,th,ht,tr,iw,uk,hi,ur,hu,vi,is,cy,id,yi',
            autoDisplay:false
        },'google_translate_element');
    }
</script>





<script>
    
    
</script>

<script data-swup-reload-script>
    
    
</script>
</footer>
</div>
        </div><a
        href="#nav"
        title="返回顶部"
        id="back-top"
        class="fixed right-6 bottom-9 z-10 translate-y-3 scale-90 cursor-pointer rounded-full bg-white opacity-0 transition duration-300 ease-[ease] dark:bg-darkBgAccent sm:scale-100"
    >
        <div class="relative">
            <div class="absolute left-0 top-0 flex h-full w-full items-center justify-center text-xl">
                <i class="eva eva-arrow-upward-outline"></i>
            </div>
            <svg id="svg" width="54" height="54" viewBox="0 0 54 54" preserveAspectRatio="xMinYMin meet">
                <circle
                    transform="rotate(-90, 27 , 27)"
                    style="stroke-dasharray: 157, 157; stroke-dashoffset: 157;"
                    cx="27"
                    cy="27"
                    r="25"
                    fill="none"
                    stroke-width="4"
                    stroke-linecap="round"
                    stroke="var(--theme)"
                />
            </svg>
        </div>
    </a><noscript>
    <style>
        .dark-mode-switch,
        #run-time,
        #bionicReading,
        .noscript-hidden,
        [data-clipboard-text],
        [data-lazyload] {
            display: none;
        }
        #back-top {
            opacity: 1;
        }
        .noscript-show {
            display: initial;
        }
    </style>
</noscript>
</body>
</html>
